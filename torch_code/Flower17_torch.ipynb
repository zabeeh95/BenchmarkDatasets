{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T15:11:41.600917900Z",
     "start_time": "2026-01-24T15:11:41.580960900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version is :  2.7.1+cu118\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch version is : \", torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zabeeh\\PycharmProjects\\DeepLearning\\CompleteProjects\\BenchmarkDatasets\n",
      "C:\\Users\\zabeeh\\PycharmProjects\\DeepLearning\\CompleteProjects\\BenchmarkDatasets\\data\\Flower17\\Flower17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Go up one level â†’ BenchmarkDatasets\n",
    "ROOT_DIR = os.path.dirname(BASE_DIR)\n",
    "print(ROOT_DIR)\n",
    "# Dataset path\n",
    "data_dir = os.path.join(\n",
    "    ROOT_DIR,\n",
    "    \"data\",\n",
    "    \"Flower17\",\n",
    "    \"Flower17\"\n",
    ")\n",
    "\n",
    "print(data_dir)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-24T15:11:41.936230300Z",
     "start_time": "2026-01-24T15:11:41.930838600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2026-01-24T15:18:55.705986500Z",
     "start_time": "2026-01-24T15:18:48.346682700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360\n",
      "['1', '10', '11', '12', '13', '14', '15', '16', '17', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "torch.Size([256, 3, 48, 48])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# loading full datatset\n",
    "dataset_full = datasets.ImageFolder(root=data_dir, transform=None)\n",
    "\n",
    "train_size = int(0.8*len(dataset_full))\n",
    "val_size = len(dataset_full) - train_size\n",
    "\n",
    "from torch.utils.data import  random_split\n",
    "\n",
    "train_dataset, val_dataset = random_split(    dataset_full, [train_size, val_size])\n",
    "\n",
    "# Define data augmentation for training\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((48, 48)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "# Simpler transform for validation (no augmentation)\n",
    "validation_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((48, 48)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = train_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "print(len(dataset_full))\n",
    "print(dataset_full.classes)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)  # torch.Size([batch_size, 3, 48, 48])\n",
    "print(labels.shape)  # torch.Size([batch_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCNN(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.25, inplace=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.25, inplace=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.25, inplace=False)\n",
      "  )\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=4608, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (output): Linear(in_features=64, out_features=17, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 48, 48]             896\n",
      "       BatchNorm2d-2           [-1, 32, 48, 48]              64\n",
      "               ELU-3           [-1, 32, 48, 48]               0\n",
      "            Conv2d-4           [-1, 32, 48, 48]           9,248\n",
      "       BatchNorm2d-5           [-1, 32, 48, 48]              64\n",
      "               ELU-6           [-1, 32, 48, 48]               0\n",
      "         MaxPool2d-7           [-1, 32, 24, 24]               0\n",
      "         Dropout2d-8           [-1, 32, 24, 24]               0\n",
      "            Conv2d-9           [-1, 64, 24, 24]          18,496\n",
      "      BatchNorm2d-10           [-1, 64, 24, 24]             128\n",
      "              ELU-11           [-1, 64, 24, 24]               0\n",
      "           Conv2d-12           [-1, 64, 24, 24]          36,928\n",
      "      BatchNorm2d-13           [-1, 64, 24, 24]             128\n",
      "              ELU-14           [-1, 64, 24, 24]               0\n",
      "        MaxPool2d-15           [-1, 64, 12, 12]               0\n",
      "        Dropout2d-16           [-1, 64, 12, 12]               0\n",
      "           Conv2d-17          [-1, 128, 12, 12]          73,856\n",
      "      BatchNorm2d-18          [-1, 128, 12, 12]             256\n",
      "              ELU-19          [-1, 128, 12, 12]               0\n",
      "           Conv2d-20          [-1, 128, 12, 12]         147,584\n",
      "      BatchNorm2d-21          [-1, 128, 12, 12]             256\n",
      "              ELU-22          [-1, 128, 12, 12]               0\n",
      "        MaxPool2d-23            [-1, 128, 6, 6]               0\n",
      "        Dropout2d-24            [-1, 128, 6, 6]               0\n",
      "          Flatten-25                 [-1, 4608]               0\n",
      "           Linear-26                   [-1, 64]         294,976\n",
      "      BatchNorm1d-27                   [-1, 64]             128\n",
      "              ELU-28                   [-1, 64]               0\n",
      "          Dropout-29                   [-1, 64]               0\n",
      "           Linear-30                   [-1, 64]           4,160\n",
      "      BatchNorm1d-31                   [-1, 64]             128\n",
      "              ELU-32                   [-1, 64]               0\n",
      "          Dropout-33                   [-1, 64]               0\n",
      "           Linear-34                   [-1, 17]           1,105\n",
      "================================================================\n",
      "Total params: 588,401\n",
      "Trainable params: 588,401\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 6.44\n",
      "Params size (MB): 2.24\n",
      "Estimated Total Size (MB): 8.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DeepCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        # Block 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        # Block 3\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        self.Flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * 6 * 6, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(64, 17)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.Flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "# model = DeepCNN().to(device)\n",
    "model = DeepCNN().to(device=device)\n",
    "print(model)\n",
    "model.apply(init_weights)\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(3, 48, 48))\n",
    "# print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-24T15:18:55.769691500Z",
     "start_time": "2026-01-24T15:18:55.713289400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimzier = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-24T15:18:55.801462100Z",
     "start_time": "2026-01-24T15:18:55.753861600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 2.1593\n",
      "Epoch 1/10 - Loss: 2.1834, Accuracy: 29.32%\n",
      "Epoch 2, Batch 0, Loss: 2.1828\n",
      "Epoch 2/10 - Loss: 2.1423, Accuracy: 31.99%\n",
      "Epoch 3, Batch 0, Loss: 2.0082\n",
      "Epoch 3/10 - Loss: 1.9682, Accuracy: 34.10%\n",
      "Epoch 4, Batch 0, Loss: 1.9563\n",
      "Epoch 4/10 - Loss: 1.9611, Accuracy: 35.75%\n",
      "Epoch 5, Batch 0, Loss: 1.8422\n",
      "Epoch 5/10 - Loss: 1.9344, Accuracy: 37.50%\n",
      "Epoch 6, Batch 0, Loss: 1.8796\n",
      "Epoch 6/10 - Loss: 1.8616, Accuracy: 38.51%\n",
      "Epoch 7, Batch 0, Loss: 1.8016\n",
      "Epoch 7/10 - Loss: 1.7523, Accuracy: 42.83%\n",
      "Epoch 8, Batch 0, Loss: 1.7788\n",
      "Epoch 8/10 - Loss: 1.7359, Accuracy: 43.38%\n",
      "Epoch 9, Batch 0, Loss: 1.7084\n",
      "Epoch 9/10 - Loss: 1.6883, Accuracy: 45.22%\n",
      "Epoch 10, Batch 0, Loss: 1.6158\n",
      "Epoch 10/10 - Loss: 1.6860, Accuracy: 45.31%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_index, (images, labels) in enumerate(train_loader):\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "\n",
    "        optimzier.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimzier.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Print progress every 10 batches\n",
    "        if batch_index % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_index}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Print epoch statistics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-24T15:24:44.196377Z",
     "start_time": "2026-01-24T15:23:33.607428900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python310_torch_gpu_general] *",
   "language": "python",
   "name": "conda-env-python310_torch_gpu_general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
